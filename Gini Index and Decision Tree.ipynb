{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "Decision Tree is a type of supervised learning model which tries to split the data into homogeneous sets to make predictions, visually this resembles a tree, shown below.\n",
    "\n",
    "\n",
    "-- Decision tree is the most powerful and popular tool for classification prediction. \n",
    "\n",
    "-- A Decision tree is a flowchart like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic_.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical Decision Tree Representation:\n",
    "\n",
    "<br>\n",
    "<img src=\"decision_tree.png\" alt=\"knn_graph\" style=\"width: 500px;\"/>\n",
    "\n",
    "pros:\n",
    "\n",
    "    Simple to understand and interpret.\n",
    "    Works better than Logistic regression in case of non-linear relationship between dependent & independent variables\n",
    "    \n",
    "con:\n",
    "\n",
    "    Tends to overfit on data with a large number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general algorithm for a decision tree can be described as follows:\n",
    "\n",
    "-- Pick the best attribute/feature. The best attribute is one which best splits or separates the data.\n",
    "\n",
    "-- Ask the relevant question.\n",
    "\n",
    "-- Follow the answer path.\n",
    "\n",
    "-- Go to step 1 until you arrive to the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical Decision Tree Representation:\n",
    "\n",
    "<br>\n",
    "<img src=\"decision_tree.png\" alt=\"knn_graph\" style=\"width: 500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy: \n",
    "\n",
    "It is used to measure the impurity or randomness of a dataset. Imagine choosing a yellow ball from a box of just yellow balls (say 100 yellow balls). \n",
    "\n",
    "    Then this box is said to have 0 entropy which implies 0 impurity or total purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now, let’s say 30 of these balls are replaced by red and 20 by blue  :\n",
    "    If we now draw another ball from the box, the probability of drawing a yellow ball will drop from 1.0 to 0.5. \n",
    "\n",
    "\n",
    "Since the impurity has increased, entropy has also increased while purity has decreased.\n",
    "\n",
    "\n",
    "Shannon’s entropy model uses the logarithm function with base 2 (log2(P(x)) to measure the entropy because as the probability P(x) of randomly drawing a yellow ball increases, the result approaches closer to binary logarithm 1\n",
    "\n",
    "<img src=\"entropy.png\" alt=\"knn_graph\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Gain: \n",
    "\n",
    "To find the best feature which serves as a root node in terms of information gain, \n",
    "\n",
    "we first use each descriptive feature and split the dataset along the values of these descriptive features and then calculate the entropy of the dataset.\n",
    "\n",
    "\n",
    "This gives us the remaining entropy once we have split the dataset along the feature values. \n",
    "\n",
    "<br>\n",
    "    \n",
    "<img src=\"infogain.png\" alt=\"knn_graph\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini Index: \n",
    "\n",
    "It is calculated by subtracting the sum of squared probabilities of each class from one. It favors larger partitions and easy to implement whereas information gain favors smaller partitions with distinct values.\n",
    "\n",
    "\n",
    "<img src=\"gini_index.png\" alt=\"knn_graph\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ce5ef14f-17ad-45a0-b075-d830fe5ac8cf",
    "_uuid": "ea713c77641889165efc207ec4f46c1df518332e"
   },
   "source": [
    "# Gini Index's step by step visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           age  income student credit_rate default\n",
      "0        youth    high      no        fair      no\n",
      "1        youth    high      no   excellent      no\n",
      "2   middle_age    high      no        fair     yes\n",
      "3       senior  medium      no        fair     yes\n",
      "4       senior     low     yes        fair     yes\n",
      "5       senior     low     yes   excellent      no\n",
      "6   middle_age     low     yes   excellent     yes\n",
      "7        youth  medium      no        fair      no\n",
      "8        youth     low     yes        fair     yes\n",
      "9       senior  medium     yes        fair     yes\n",
      "10       youth  medium     yes   excellent     yes\n",
      "11  middle_age  medium      no   excellent     yes\n",
      "12  middle_age    high     yes        fair     yes\n",
      "13      senior  medium      no   excellent      no\n"
     ]
    }
   ],
   "source": [
    "# Defining a simple dataset\n",
    "attribute_names =  ['age', 'income','student', 'credit_rate']\n",
    "class_name = 'default'\n",
    "data1 ={\n",
    "    'age' : ['youth', 'youth', 'middle_age', 'senior', 'senior', 'senior','middle_age', 'youth', 'youth', 'senior', 'youth', 'middle_age','middle_age', 'senior'],\n",
    "    'income' : ['high', 'high', 'high', 'medium', 'low', 'low', 'low', 'medium','low', 'medium', 'medium', 'medium', 'high', 'medium'],\n",
    "    'student' : ['no','no','no','no','yes','yes','yes','no','yes','yes','yes','no','yes','no'],\n",
    "    'credit_rate' : ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'fair', 'fair','excellent', 'excellent', 'fair', 'excellent'],\n",
    "    'default' : ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes','yes', 'yes', 'yes', 'no']\n",
    "}\n",
    "df1 = pd.DataFrame (data1, columns=data1.keys())\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in each class is:\n",
      "yes    9\n",
      "no     5\n",
      "Name: default, dtype: int64\n",
      "\n",
      "Gini Impurity of the class is 0.459\n"
     ]
    }
   ],
   "source": [
    "#Calculate gini(D)\n",
    "def gini_impurity (value_counts):\n",
    "    n = value_counts.sum()\n",
    "    p_sum = 0\n",
    "    for key in value_counts.keys():\n",
    "        p_sum = p_sum  +  (value_counts[key] / n ) * (value_counts[key] / n ) \n",
    "    gini = 1 - p_sum\n",
    "    return gini\n",
    "\n",
    "class_value_counts = df1[class_name].value_counts()\n",
    "print(f'Number of samples in each class is:\\n{class_value_counts}')\n",
    "\n",
    "gini_class = gini_impurity(class_value_counts)\n",
    "print(f'\\nGini Impurity of the class is {gini_class:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini for age is 0.343\n",
      "Gini for income is 0.440\n",
      "Gini for student is 0.367\n",
      "Gini for credit_rate is 0.429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculating  gini impurity for the attiributes\n",
    "def gini_split_a(attribute_name):\n",
    "    attribute_values = df1[attribute_name].value_counts()\n",
    "    gini_A = 0 \n",
    "    for key in attribute_values.keys():\n",
    "        df_k = df1[class_name][df1[attribute_name] == key].value_counts()\n",
    "        n_k = attribute_values[key]\n",
    "        n = df1.shape[0]\n",
    "        gini_A = gini_A + (( n_k / n) * gini_impurity(df_k))\n",
    "    return gini_A\n",
    "\n",
    "gini_attiribute ={}\n",
    "for key in attribute_names:\n",
    "    gini_attiribute[key] = gini_split_a(key)\n",
    "    print(f'Gini for {key} is {gini_attiribute[key]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value of Gini Impurity : 0.343 \n",
      "The maximum value of Gini Gain     : 0.657 \n",
      "The selected attiribute is:  age\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute Gini gain values to find the best split\n",
    "# An attribute has maximum Gini gain is selected for splitting.\n",
    "\n",
    "min_value = min(gini_attiribute.values())\n",
    "print('The minimum value of Gini Impurity : {0:.3} '.format(min_value))\n",
    "print('The maximum value of Gini Gain     : {0:.3} '.format(1-min_value))\n",
    "\n",
    "selected_attribute = min(gini_attiribute.keys())\n",
    "print('The selected attiribute is: ', selected_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
