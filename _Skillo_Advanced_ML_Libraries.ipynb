{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning algorithms:\n",
    "\n",
    "Presense of training data with predictors (features) and correct answer (labels).\n",
    "Model uses training data to learn the relationship between features and labels.\n",
    "\n",
    "#### Regression: \n",
    "\n",
    "Predict a Continuous number \n",
    "\n",
    "    Simple Linear Regression\n",
    "    Multiple Linear Regression\n",
    "    Polynomial Regression\n",
    "    SVR\n",
    "    Decision Tree Regression\n",
    "    Random Forest\n",
    "    \n",
    "    \n",
    "#### Classification: \n",
    "\n",
    "Predict a category. \n",
    "\n",
    "    Logistic Regression\n",
    "    K-Nearest Neighbors (KNN)\n",
    "    Support Vector Machine (SVM)\n",
    "    Naive Bayes\n",
    "    Decision Tree Classification\n",
    "    Random Forest Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un-supervised learning algorithms:\n",
    "\n",
    "Absense of output data. \n",
    "Machine tries to group unsorted information based on patterns without any prior training of data.\n",
    "\n",
    "#### Clustering: \n",
    "\n",
    "    Grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups.\n",
    "\n",
    "#### Anomaly detection:\n",
    "\n",
    "    Identification of items, events or observations which do not conform to an expected pattern or other items in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Handling Missing Data\n",
    "\n",
    "    pandas dropna, fillna\n",
    "\n",
    "Data Cleaning, formatting\n",
    "\n",
    "Encoding categorical data\n",
    "\n",
    "    pandas get_dummies\n",
    "    sklearn LabelEncoder, OneHotEncoder\n",
    "\n",
    "Splitting the data into Train and Test\n",
    "    \n",
    "    sklearn train_test_split\n",
    "\n",
    "Feature Scaling:\n",
    "    \n",
    "    Standardization: (x - mean(x)) / std(x) sklearn StandardScaler\n",
    "    Normalization: (x - min(x)) / (max(x) - min(x)) sklearn MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic Regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function. These probabilities can be converted into class predictions\n",
    "\n",
    "The regression coefficient is the estimated increase in the log odds of the outcome per unit increase in the value of the condition.\n",
    "\n",
    "> $$F(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "It returns a probability score between 0 and 1. \n",
    "Map this to a discrete class by selecting a threshold value.\n",
    "\n",
    "eg: Student passed or failed in a test\n",
    "\n",
    "    p >= 0.6, class=1\n",
    "    p < 0.6, class=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Function\n",
    "\n",
    "Fitting logistic regression curve to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x201dd564a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10., 10., 0.2)\n",
    "y = 1. / (1. + np.exp(-x))\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function in Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGRW3iEiY+f8L3j8WIdAB+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x201dcccc780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.01, 1., 0.001)\n",
    "y = -np.log(x)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying classification algorithms on mushrooms dataset ( Boolean classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color   ...   stalk-surface-below-ring  \\\n",
       "0            c         n          k   ...                          s   \n",
       "1            c         b          k   ...                          s   \n",
       "2            c         b          n   ...                          s   \n",
       "3            c         n          n   ...                          s   \n",
       "4            w         b          k   ...                          s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mushrooms.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                       False\n",
       "cap-shape                   False\n",
       "cap-surface                 False\n",
       "cap-color                   False\n",
       "bruises                     False\n",
       "odor                        False\n",
       "gill-attachment             False\n",
       "gill-spacing                False\n",
       "gill-size                   False\n",
       "gill-color                  False\n",
       "stalk-shape                 False\n",
       "stalk-root                  False\n",
       "stalk-surface-above-ring    False\n",
       "stalk-surface-below-ring    False\n",
       "stalk-color-above-ring      False\n",
       "stalk-color-below-ring      False\n",
       "veil-type                   False\n",
       "veil-color                  False\n",
       "ring-number                 False\n",
       "ring-type                   False\n",
       "spore-print-color           False\n",
       "population                  False\n",
       "habitat                     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()\n",
    "#df['cap-color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    4208\n",
       "p    3916\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical features/label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0      1          5            2          4        1     6                1   \n",
       "1      0          5            2          9        1     0                1   \n",
       "2      0          0            2          8        1     3                1   \n",
       "3      1          5            3          8        1     6                1   \n",
       "4      0          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color   ...     stalk-surface-below-ring  \\\n",
       "0             0          1           4   ...                            2   \n",
       "1             0          0           4   ...                            2   \n",
       "2             0          0           5   ...                            2   \n",
       "3             0          1           5   ...                            2   \n",
       "4             1          0           4   ...                            2   \n",
       "\n",
       "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
       "0                       7                       7          0           2   \n",
       "1                       7                       7          0           2   \n",
       "2                       7                       7          0           2   \n",
       "3                       7                       7          0           2   \n",
       "4                       7                       7          0           2   \n",
       "\n",
       "   ring-number  ring-type  spore-print-color  population  habitat  \n",
       "0            1          4                  2           3        5  \n",
       "1            1          4                  3           2        1  \n",
       "2            1          4                  3           2        3  \n",
       "3            1          4                  2           3        5  \n",
       "4            1          0                  3           0        1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.95261538461538464, array([[820,  32],\n",
       "        [ 45, 728]], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 1:23].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "#split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Fitting logistic regression to training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.95569230769230773, array([[820,  32],\n",
       "        [ 40, 733]], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "X = df.iloc[:, 1:23].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "#split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Fitting logistic regression to training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic regression for multi class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://image.slidesharecdn.com/linearmodelsandmulticlassclassification2-170312171304/95/linear-models-and-multiclass-classification-22-638.jpg?cb=148933888\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iris = pd.read_csv('iris.csv')\n",
    "iris=pd.read_csv('iris.csv').drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "iris['Species'] = iris['Species'].map({'setosa': 0, 'versicolor': 1, 'virginica': 2}) # is setosa or not\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = iris.iloc[:, :-1].values\n",
    "y = iris.iloc[:, -1].values\n",
    "\n",
    "#split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "#Fitting logistic regression to training set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0],\n",
       "       [ 0, 12,  1],\n",
       "       [ 0,  0,  6]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.wso2.com/download/attachments/56989889/Multi_Class_Classification.png?version=1&modificationDate=1473828402000&api=v2\" alt=\"logisticRegressionCost\" style=\"width: 100;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Naive Bayes algorithm is a simple yet effective algorithm for most use cases. This is a probabilistic model implementing Bayes' Theorem, which is shown as something like this: \n",
    "\n",
    "> $$P(A | B) = \\frac {P(A)P(B | A)} {P(B)}$$\n",
    "\n",
    "\n",
    "This is an excellent formula for classification problems. Practically the implementation is something like this:\n",
    "> $$ P(Class_k | x_1......x_n) = P(Class_k) \\prod_{i=1}^n p(x_i | Class_k) $$\n",
    "> $$ y_h = argmax[ P(Class_k) \\prod_{i=1}^n p(x_i | Class_k) ] $$\n",
    "\n",
    "Naive Bayes Example:\n",
    "    \n",
    "<br>\n",
    "\n",
    "So, let's say we have data on 1000 pieces of fruit. The fruit being a Banana, Orange or some Other fruit and imagine we know 3 features of each fruit, whether it’s long or not, sweet or not and yellow or not, as displayed in the table below:\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"nb_new2.png\" alt=\"NB\" style=\"width: 600;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from the table what do we already know?\n",
    "\n",
    "- 50% of the fruits are bananas\n",
    "\n",
    "- 30% are oranges\n",
    "\n",
    "- 20% are other fruits\n",
    "\n",
    "<br>\n",
    "Based on our training set we can also say the following:\n",
    "\n",
    "- From 500 bananas 400 (0.8) are Long, 350 (0.7) are Sweet and 450 (0.9) are Yellow\n",
    "- Out of 300 oranges 0 are Long, 150 (0.5) are Sweet and 300 (1) are Yellow\n",
    "- From the remaining 200 fruits, 100 (0.5) are Long, 150 (0.75) are Sweet and 50 (0.25) are Yellow\n",
    "Which should provide enough evidence to predict the class of another fruit as it’s introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which should provide enough evidence to predict the class of another fruit as it’s introduced.\n",
    "\n",
    "So let’s say we’re given the features of a piece of fruit and we need to predict the class. \n",
    "\n",
    "<br>If we’re told that the additional fruit is Long, Sweet and Yellow, we can classify it using the following formula and subbing in the values for each outcome, whether it’s a Banana, an Orange or Other Fruit. The one with the highest probability (score) being the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nb_new3.png\" alt=\"NB\" style=\"width: 600;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion -\n",
    "\n",
    "In this case, based on the higher score 0.01875 < 0.252 we can assume this Long, Sweet and Yellow fruit is, in fact, a Banana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pros: \n",
    "\n",
    "    Naive assumption of independence between every pair of features\n",
    "    Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods\n",
    "    \n",
    "##### con:\n",
    "\n",
    "    Can not learn relationship between features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian NB: It assumes that the features follow a normal distribution.\n",
    "\n",
    "MultiNomial NB: It is suitable for discrete features. Eg: word counts for text classification\n",
    "\n",
    "Bernoulli NB: For discreet features, like MuliNomianNB. MultinomialNB works with occurrence counts,\n",
    "    BernoulliNB is designed for binary/boolean features\n",
    "    \n",
    "Note: Multinomial distributions can not contain negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91569230769230769, array([[773,  79],\n",
       "        [ 58, 715]], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "X = df.iloc[:, 1:23].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "#split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82769230769230773, array([[787,  65],\n",
       "        [215, 558]], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred = bnb.predict(X_test)\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html#classification\n",
    "\n",
    "SVM is one if the most versitile algorithms out there and can be used for a wide varity of application. This algorithm a inherently binary classifier which split a feature vectors into two parts. Suppose we have a feature vectors(compressed into a 2-D space) for Dogs and Cats and are plotted using a scatter plot. \n",
    "\n",
    "This seperation is done by pushing the hyperline as furthur away from the data clusters furthest vectors called \"support vectors\".\n",
    "\n",
    "This hyperplane can be defined by this simple equation: \n",
    ">  $$y = w * x + b$$\n",
    "\n",
    "Where the goal is the find the best value of 'w' which seperates the clusters the best way. 'w' can be correctly estimated by a loss function.\n",
    "\n",
    "Visualization of the SVM: \n",
    "\n",
    "<img src=\"SVM.png\" alt=\"knn_graph\" style=\"width: 200;\"/>\n",
    "\n",
    "    Finds hyperplanes separating labels\n",
    "    Support vectors are the data points nearest to the hyperplane\n",
    "    Get the margin for each hyperplane\n",
    "    Select the optimal hyperplane (one with the highest margin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, array([[852,   0],\n",
       "        [  0, 773]], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting SVM to training set\n",
    "from sklearn import svm\n",
    "svm = svm.SVC()\n",
    "svm.fit(X_train, y_train)  \n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "Decision Tree is a type of supervised learning model which tries to split the data into homogeneous sets to make predictions, visually this resembles a tree, shown below.\n",
    "\n",
    "Typical Decision Tree Representation:\n",
    "\n",
    "<br>\n",
    "<img src=\"https://www.digitalvidya.com/wp-content/uploads/2018/05/DicisionTree-1024x391.png\" alt=\"knn_graph\" style=\"width: 600;\"/>\n",
    "\n",
    "\n",
    "pros:\n",
    "\n",
    "    Simple to understand and interpret.\n",
    "    Works better than Logistic regression in case of non-linear relationship between dependent & independent variables\n",
    "    \n",
    "con:\n",
    "\n",
    "    Tends to overfit on data with a large number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, array([[852,   0],\n",
       "        [  0, 773]], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "KNN is a algorithm which can be used both for regression and classification problems. KNN is a lazy learning algorithm which means it does not retain any information of what it has learned from the training data but rather keeps the data handy to make predictions.\n",
    "\n",
    "The algorithm works this way:\n",
    "1. Store all the feature vectors with there mapping that is the class they were assigned to, let's say \n",
    "> $$ X_i -> Y_i $$\n",
    "2. Take a unknown feature vector which has to be classified say 'u'.\n",
    "3. Calculate the distance of all the k neighbors where k is user defined which is nothing but a parameter which defined how many neighbors in the dataset around 'u' is to be considered. \n",
    "4. The k neighbors are calculated using *Euclidean Distance* which is something like this \n",
    "> #### $$ distance = \\sqrt{\\sum_{i=0}^{n}(x_j - x_i )^ 2} $$ \n",
    "5. Once the k neighbors are found find there class and based on population of the k neighbors class assign the most common class to the 'u'.\n",
    "\n",
    "\n",
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-5ec1cba17b824a46e4e55295c48c3379\" alt=\"knn_graph\" style=\"width: 300px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99692307692307691"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "predictions = knn_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newer concept, first proposed in 1995.\n",
    "\n",
    "A random forest is basically a combination of bagging with trees. You have the freedom to using any model in bagging, when you use a tree-based model then it’s called a random forest.\n",
    "\n",
    "Random forest is an ensemble model built with a collection of decision tree classifiers. Each decision tree classifier works on random subset of data with random number of features. \n",
    "\n",
    "Multiple decision trees from training data and output the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
    "\n",
    "Random decision forests correct the decision trees' habit of overfitting to their training set\n",
    "\n",
    "Visualization of the Random Forest Classifier: \n",
    "\n",
    "<img src=\"RandomF.png\" alt=\"knn_graph\" style=\"width: 200;\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"RandomF2.png\" alt=\"knn_graph\" style=\"width: 200;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RandomF3.png\" alt=\"knn_graph\" style=\"width: 200;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages of Random Forest\n",
    "- It reduces overfitting in decision trees and helps to improve the accuracy\n",
    "\n",
    "- It is flexible to both classification and regression problems\n",
    "\n",
    "- It works well with both categorical and continuous values\n",
    "\n",
    "- It automates missing values present in the data\n",
    "\n",
    "- Normalising of data is not required as it uses a rule-based approach.\n",
    "\n",
    "<br>\n",
    "However, despite these advantages, a random forest algorithm also has some drawbacks.\n",
    "\n",
    "- It requires much computational power as well as resources as it builds numerous trees to combine their outputs. \n",
    "\n",
    "- It also requires much time for training as it combines a lot of decision trees to determine the class.\n",
    "\n",
    "- Due to the ensemble of decision trees, it also suffers interpretability and fails to determine the significance of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=5)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
